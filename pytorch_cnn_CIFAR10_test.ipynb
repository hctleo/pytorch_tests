{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_cnn_CIFAR10_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mechhector/pytorch_tests/blob/main/pytorch_cnn_CIFAR10_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37s5RY8Nyp3i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "import torchvision.transforms as T\n",
        "import seaborn as sn\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = '/content/drive/MyDrive/datasets'\n",
        "DATA_DIR = '/content/drive/MyDrive/datasets/cifar10'\n",
        "CATEGORIES = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "def get_path(relpath):\n",
        "  return os.path.join(BASE_DIR, relpath)"
      ],
      "metadata": {
        "id": "aJrcdT40zglE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_train = CIFAR10(DATA_DIR, train=True, download=True)\n",
        "cifar10_test = CIFAR10(DATA_DIR, train=False, download=True)"
      ],
      "metadata": {
        "id": "cZ_rflM2zip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(len(cifar10_train), len(cifar10_test))"
      ],
      "metadata": {
        "id": "6LaOY09izo5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep_transform = T.Compose([T.ToTensor(), T.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
        "\n",
        "# Applying a transform\n",
        "tensor_train = CIFAR10(DATA_DIR, train=True, download=False, transform=prep_transform)\n",
        "tensor_test = CIFAR10(DATA_DIR, train=False, download=False, transform=prep_transform)\n",
        "\n",
        "# Normalizing data\n",
        "imgs = torch.stack([img_t for img_t, _ in tensor_train], dim=3)\n",
        "imgs.shape"
      ],
      "metadata": {
        "id": "HliJPSjYzxs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloaders\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(tensor_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(tensor_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "jdWOrS270WyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pgdinamica\n",
        "\n",
        "class MLPClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    \n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(3 * 32*32, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 10),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    v = self.flatten(x)\n",
        "    return self.layers(v)\n",
        "\n"
      ],
      "metadata": {
        "id": "fryMq2zh11zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Rodando na {device}\")\n",
        "\n",
        "model = MLPClassifier().to(device)"
      ],
      "metadata": {
        "id": "J4ZT-ZVi2BsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "xKQKL6-E2G-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn training\n",
        "\n",
        "def train(model, dataloader, loss_func, optimizer):\n",
        "  model.train()\n",
        "  cumloss = 0.0\n",
        "\n",
        "  for imgs, labels in dataloader:\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred = model(imgs)\n",
        "\n",
        "    loss = loss_func(pred, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cumloss += loss.item()\n",
        "\n",
        "  return cumloss / len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, loss_func):\n",
        "  model.eval()\n",
        "  cumloss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for imgs, labels in dataloader:\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "      pred = model(imgs)\n",
        "      loss = loss_func(pred, labels)\n",
        "      cumloss += loss.item()\n",
        "\n",
        "  return cumloss / len(dataloader)\n",
        "\n",
        "epochs = 60\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "for t in range(epochs):\n",
        "  train_loss = train(model, train_loader, loss_func, optimizer)\n",
        "  train_losses.append(train_loss)\n",
        "  if t % 20 == 0:\n",
        "    print(f\"Epoch: {t}; Train Loss: {train_loss}\")\n",
        "  \n",
        "  test_loss = validate(model, test_loader, loss_func)\n",
        "  test_losses.append(test_loss)"
      ],
      "metadata": {
        "id": "GSBdf9sP2w-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results evaluation\n",
        "\n",
        "def make_confusion_matrix(model, loader, n_classes):\n",
        "  confusion_matrix = torch.zeros(n_classes, n_classes, dtype=torch.int64)\n",
        "  with torch.no_grad():\n",
        "    for i, (imgs, labels) in enumerate(loader):\n",
        "      imgs = imgs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(imgs)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      for t, p in zip(torch.as_tensor(labels, dtype=torch.int64).view(-1), \n",
        "                      torch.as_tensor(predicted, dtype=torch.int64).view(-1)):\n",
        "        confusion_matrix[t, p] += 1\n",
        "  return confusion_matrix\n",
        "\n",
        "def evaluate_accuracy(model, dataloader, classes, verbose=True):\n",
        "  # prepare to count predictions for each class\n",
        "  correct_pred = {classname: 0 for classname in classes}\n",
        "  total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "  confusion_matrix = make_confusion_matrix(model, dataloader, len(classes))\n",
        "  if verbose:\n",
        "    total_correct = 0.0\n",
        "    total_prediction = 0.0\n",
        "    for i, classname in enumerate(classes):\n",
        "      correct_count = confusion_matrix[i][i].item()\n",
        "      class_pred = torch.sum(confusion_matrix[i]).item()\n",
        "\n",
        "      total_correct += correct_count\n",
        "      total_prediction += class_pred\n",
        "\n",
        "      accuracy = 100 * float(correct_count) / class_pred\n",
        "      print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                    accuracy))\n",
        "  print(\"Global acccuracy is {:.1f}\".format(100 * total_correct/total_prediction))\n",
        "  return confusion_matrix\n",
        "\n",
        "def test(model, dataloader, classes):\n",
        "  # prepare to count predictions for each class\n",
        "  correct_pred = {classname: 0 for classname in classes}\n",
        "  total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "  # again no gradients needed\n",
        "  with torch.no_grad():\n",
        "      for images, labels in dataloader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predictions = torch.max(outputs, 1)\n",
        "          # collect the correct predictions for each class\n",
        "          for label, prediction in zip(labels, predictions):\n",
        "              if label == prediction:\n",
        "                  correct_pred[classes[label]] += 1\n",
        "              total_pred[classes[label]] += 1\n",
        "\n",
        "  # print accuracy for each class\n",
        "  total_correct = 0.0\n",
        "  total_prediction = 0.0\n",
        "  for classname, correct_count in correct_pred.items():\n",
        "      total_correct += correct_count\n",
        "      total_prediction += total_pred[classname]\n",
        "      accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "      print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                    accuracy))\n",
        "  print(\"Global acccuracy is {:.1f}\".format(100 * total_correct/total_prediction))\n",
        "\n"
      ],
      "metadata": {
        "id": "dyAPoQ6k4OJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Confusion matrix\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(confusion_matrix.tolist(), \n",
        "           annot=True, annot_kws={\"size\": 16}, fmt='d')"
      ],
      "metadata": {
        "id": "lzLZB4mR4cTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building cnn model\n",
        "\n",
        "class ConvolutionalModel(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.convlayers = nn.Sequential(\n",
        "        nn.Conv2d(3, 16, kernel_size=(3, 3)),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "\n",
        "        nn.Conv2d(16, 32, kernel_size=(3, 3)),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "\n",
        "      )\n",
        "\n",
        "      self.linearlayers = nn.Sequential(\n",
        "          nn.Linear(1152, 256),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(256, 10)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.convlayers(x)\n",
        "      x = torch.flatten(x, 1)\n",
        "      return self.linearlayers(x)"
      ],
      "metadata": {
        "id": "5WcCTEe84rNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convmodel = ConvolutionalModel().to(device)\n",
        "\n",
        "loss_func2 = nn.CrossEntropyLoss()\n",
        "optimizer2 = torch.optim.SGD(convmodel.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "WYUrH95x4vDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 60\n",
        "conv_train_losses = []\n",
        "conv_test_losses = []\n",
        "for t in range(epochs):\n",
        "  train_loss = train(convmodel, train_loader, loss_func2, optimizer2)\n",
        "  conv_train_losses.append(train_loss)\n",
        "  if t % 10 == 0:\n",
        "    print(f\"Epoch: {t}; Train Loss: {train_loss}\")\n",
        "  test_loss = validate(convmodel, test_loader, loss_func2)\n",
        "  conv_test_losses.append(test_loss)  "
      ],
      "metadata": {
        "id": "7_vcyQgH402w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_confusion_matrix = evaluate_accuracy(convmodel, test_loader, CATEGORIES)"
      ],
      "metadata": {
        "id": "KkpUq-v249t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot confusion matrix\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(confusion_matrix.tolist(), \n",
        "           annot=True, annot_kws={\"size\": 16}, fmt='d')"
      ],
      "metadata": {
        "id": "YgMn1mqH4-QA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}